% Это основная команда, с которой начинается любой \LaTeX-файл. Она отвечает за тип документа, с которым связаны основные правил оформления текста.
\documentclass{article}

% Здесь идет преамбула документа, тут пишутся команды, которые настраивают LaTeX окружение, подключаете внешние пакеты, определяете свои команды и окружения. В данном случае я это делаю в отдельных файлах, а тут подключаю эти файлы.

% Здесь я подключаю разные стилевые пакеты. Например возможности набирать особые символы или возможность компилировать русский текст. Подробное описание внутри.
\usepackage{packages}

% Здесь я определяю разные окружения, например, теоремы, определения, замечания и так далее. У этих окружений разные стили оформления, кроме того, эти окружения могут быть нумерованными или нет. Все подробно объяснено внутри.
\usepackage{environments}

% Здесь я определяю разные команды, которых нет в LaTeX, но мне нужны, например, команда \tr для обозначения следа матрицы. Или я переопределяю LaTeX команды, которые работают не так, как мне хотелось бы. Типичный пример мнимая и вещественная часть комплексного числа \Im, \Re. В оригинале они выглядят не так, как мы привыкли. Кроме того, \Im еще используется и для обозначения образа линейного отображения. Подробнее описано внутри.
\usepackage{commands}

% Пакет для титульника проекта
\usepackage{titlepage}

% Здесь задаем параметры титульной страницы
\setUDK{192.168.1.1}
% Выбрать одно из двух
% \setToResearch
\setToProgram

\setTitle{Нейросети с нуля}

% Выбрать одно из трех:
% КТ1 -- \setStageOne
% КТ2 -- \setStageTwo
% Финальная версия -- \setStageFinal
\setStageOne
%\setStageTwo
%\setStageFinal

\setGroup{204}
%сюда можно воткнуть картинку подписи
\setStudentSgn{\includegraphics[scale=0.15]{sgn.jpeg}}
\setStudent{Гимранов Артур Маратович}
\setStudentDate{03.02.2022}
\setAdvisor{Дмитрий Витальевич Трушин}
\setAdvisorTitle{доцент, к.ф.-м.н.}
\setAdvisorAffiliation{ФКН НИУ ВШЭ}
\setAdvisorDate{}
\setGrade{}
%сюда можно воткнуть картинку подписи
\setAdvisorSgn{}
\setYear{2022}


% С этого момента начинается текст документа
\begin{document}

% Эта команда создает титульную страницу
\makeTitlePage

% Здесь будет автоматически генерироваться содержание документа
\tableofcontents

% Данное окружение оформляет аннотацию: краткое описание текста выделенным абзацем после заголовка

\newpage

\begin{abstract}
В рамках этого проекта предполагается изучить теорию нейросетей и их обучения и написать проект в котором будут реализованы все необходимые компоненты для работы и обучения нейросети.
\end{abstract}


\section{Введение}

В проекте я реализую следующие компоненты: узел нейросети, который состоит из линейного отображения и нелинейной части, объекты отвечающие функциям штрафа. Будет реализован механизм вычисления градиента для узла и проталкивания градиента в узлы предыдущего слоя. На основе этого механизма будут написаны методы обучения нейросети. Таким образом передо мной стоят следующие задачи:
\begin{enumerate}
    \item изучить теорию нейросетей и градиентоного спуска
    \item кратко изложить в отчете теорию
    \item имплементировать необходимые классы и структуры
    \item изложить в отчете архитектуру и дизайн имплементации
    \item написать сопроводительную документацию.
\end{enumerate}


Теперь про общую постановку задачи. У нас есть $k$ переменных $x = [x^{(1)}, \dots, x^{(k)}]^t$, через которые мы хотим выразить переменную $y$ в виде некоторой функции:
$$
f(x) = y
$$
Понятно, что для $n$ векторов и образов эта задача решается очень легко, нам же хочется обучить модель по начальной выборке, чтобы ошибка на других векторах была минимальна

Как будем искать приближение? Давайте для простоты рассмотрим двухслойную нейросеть. Нейроном будем называть блок в которой мы подаем вектор $\in \R^n$, а он нам возвращает вектор $\in \R^m$, и сам обладает каким-то набором параметров $\theta$, будем говорить что это такая функция
$$
f(x, \theta): \R^n \rightarrow \R^m
$$
Теперь разберем пример из двух блоков. Пусть у нас есть два блока с параметрами $\theta_1, \theta_2$ и у нас выполняется такая цепочка функций

$$
\R^n \xrightarrow[]{x_i} \underset{f(x, \theta_1)}{\boxed{\theta_1}} \xrightarrow[]{w_i} \underset{g(x, \theta_2)}{\boxed{\theta_2}} \xrightarrow[]{z_i} \R^m
$$
Тогда мы хотим подобрать такие параметры $\theta_1, \theta_2$, чтобы минимизировать ошибку на обучающей выборке $x_i \in \R^n, y_i \in \R^m$.
$$
\begin{bmatrix}
x_1\\
\vdots\\
x_p
\end{bmatrix}
\rightarrow
\begin{bmatrix}
y_1\\
\vdots\\
y_p
\end{bmatrix}
$$
Функция ошибки $\phi(\theta_1, \theta_2) = \Sum{i = 1}{p} \|g(f(x_i, \theta_1), \theta_2) - y_i\|^2 \rightarrow \underline{\min}$. Теперь мы хотим посчитать градиент по параметрам $\theta_1, \theta_2$ и градиентным спуском минимизирвать ошибку

\section{Важный пример}

Рассмотрим задачу. Допустим мы хотим найти зависимость цены квартиры от некоторого набора параметров: жилой площади, расстояния до метро, расстояния до центра. Представьте, что мы измеририли все эти параметры для $n$ квартир и получили наборы значений. Цену сложим в $y_i$, а параметры в вектора
$x_i =[x_i^{(1)}, x_i^{(2)}, x_i^{(3)}]^t$. И мы хотим подобрать функцию $f$, чтобы $f(x_i) = y_i$. Конечно нет строгой зависимости подходящей любой квартире, но мы можем подобрать функцию в некотором виде, для которой отклонение в наших точках было бы наименьшим:

$$
\Sum{i = 0}{n} |f(x_i) - y_i| \rightarrow \min
$$

% \section{Описание функциональных и нефункциональных требований к программному проекту}
\section{Функциональные требования}
Наша программа будет получать на вход обучающую выборку подбирать по ней параметры и вычислять предполагаемое значение в точке.
\begin{enumerate}
\item \texttt{Net}. Инцилизирует ресурсы, слои нейронки и блок функции ошибок. Главный класс проекта, нужен для обучения и предсказания значения в точке.
\item \texttt{ComputeBlock}.  Те самые слои нейронки или наши "блоки". Содержит функцию и ее параметры. Умеет вычислять функцию в точке, считать градиент по параметрам и проталкивать его в следующий блок.
\item \texttt{LosFunction}. Функция ошибок, нужна для расчета отклонения и вычисления градиента
\end{enumerate}

\section{Нефункциональные требования}

\begin{itemize}
    \item C++20~\cite{cpp}
    \item Google C++ Style Guide~\cite{styleguide}
    \item GNU GCC compiler~\cite{gcc}
    \item ClangFormat linter~\cite{clangformat}
    \item Библиотеки: Eigen~\cite{eigen}, glm~\cite{glm}, cuBlas~\cite{cublas}
    \item Система поддержки версий: git~\cite{git} с github~\cite{github}
\end{itemize}

% Напишем программу на C++, для работы с линейной алгеброй и матрицами будем использовать библиотеки Eigen, glm, cuBlas.

% За все будет отвечать класс Net, в нем будет функция train, для подбора параметров $\theta_1, \theta_2$ по обучающей выборке, функция eval, для предсказывания значения в точке, а также объект класса LosFunction для оценки ошибки при вычислении параметров

% Для обучения у нас будет класс блоков ComputeBlock, в которых будут храниться функции $f, g$, а также соотвествующие параметры $\theta_1, \theta_2$. Там будут методы $eval$ для вычисления функции в точке, $grad$ для подсчета градиента по параметрам и вспомогательные для этого функции.

\section{Календарный план}

\begin{enumerate}
    \item Изучить теорию нейросетей и градиентного спуска до 15.02.2022
    \item Имплементировать необходимые структуры для работы с одним полносвязным слоем нейросети до 01.03.2022
    \item Имплементировать необходимые структуры для работы с разными функциями потерь до 15.03.2022
    \item Имплементировать алгоритм градиентного спуска. 01.04.2022
    \item Имплементированы все необходимые классы для работы и обучения игрушечной нейросети. 15.04.2022
    \item Написать сопроводительную документацию до 01.05.2022
    \item Подготовить финальный отчет до 15.05.2022


\end{enumerate}

% \section{Содержательная часть}

% Здесь идет планомерное изложение информации от начала до конца. Тут не нужна никакая философия или объяснения, все это было во введении. Тут сухой математический текст с определениями, формулировками и где надо доказательствами. Содержательную часть можно бить на части, чтобы структурировать изложение.

% \subsection{Содержательная часть 1}

% \subsection{Содержательная часть 2}

% Здесь автоматически генерируется библиография. Первая команда задает стиль оформления библиографии, а вторая указывает на имя файла с расширением bib, в котором находится информация об источниках.
\bibliographystyle{plainurl}
\bibliography{bibl}



% % С этого момента глобальная нумерация идет буквами. Этот раздел я добавил лишь для демонстрации возможностей LaTeX, его можно и нужно удалить и он не нужен для курсового проекта непосредственно.
% \appendix

% Проведем небольшой обзор возможностей \LaTeX. Далее идет обзорный кусок, который надо будет вырезать. Он приведен лишь для демонстрации возможностей \LaTeX.

% \section{Нумеруемый заголовок}
% Текст раздела
% \subsection{Нумеруемый подзаголовок}
% Текст подраздела
% \subsubsection{Нумеруемый подподзаголовок}
% Текст подподраздела

% \section*{Не нумеруемый заголовок}
% Текст раздела
% \subsection*{Не нумеруемый подзаголовок}
% Текст подраздела
% \subsubsection*{Не нумеруемый подподзаголовок}
% Текст подподраздела


% \paragraph{Заголовок абзаца} Текст абзаца

% Формулы в тексте набирают так $x = e^{\pi i}\sqrt{\text{формула}}$. Выключенные не нумерованные формулы набираются либо так:
% \[
% x = e^{\pi i}\sqrt{\text{формула}}
% \]
% Либо так
% $$
% x = e^{\pi i}\sqrt{\text{формула}}
% $$
% Первый способ предпочтительнее при подаче статей в журналы AMS, потому рекомендую привыкать к нему.

% Выключенные нумерованные формулы:
% \begin{equation}\label{Equation1}
% % \label{имя-метки} эта команда ставит метку, на которую потом можно сослаться с помощью \ref{имя-метки}. Метки можно ставить на все объекты, у которых есть автоматические счетчики (номера разделов, подразделов, теорем, лемм, формул и т.д.
% x = e^{\pi i}\sqrt{\text{формула}}
% \end{equation}
% Или не нумерованная версия
% \begin{equation*}
% x = e^{\pi i}\sqrt{\text{формула}}
% \end{equation*}

% Уравнение~\ref{Equation1} радостно занумеровано.

% Лесенка для длинных формул
% \begin{multline}
% x = e^{\pi i}\sqrt{\text{очень очень очень длинная формула}}=\\
% \tr A - \sin(\text{еще одна очень очень длинная формула})=\\
% \cos z \Im \varphi(\text{и последняя длинная при длинная формула})
% \end{multline}

% Многострочная формула с центровкой
% \begin{gather}
% x = e^{\pi i}\sqrt{\text{очень очень очень длинная формула}}=\\
% \tr A - \sin(\text{еще одна очень очень длинная формула})=\\
% \cos z \Im \varphi(\text{и последняя длинная при длинная формула})
% \end{gather}

% Многострочная формула с ручным выравниванием. Выравнивание идет по знаку $\&$, который на печать не выводится.
% \begin{align}
% x = &e^{\pi i}\sqrt{\text{очень очень очень длинная формула}}=\\
% &\tr A - \sin(\text{еще одна очень очень длинная формула})=\\
% &\cos z \Im \varphi(\text{и последняя длинная при длинная формула})
% \end{align}

% \begin{theorem}
% Текст теоремы
% \end{theorem}
% \begin{proof}
% В специальном окружении оформляется доказательство.
% \end{proof}

% \begin{theorem}[Имя теоремы]
% Текст теоремы
% \end{theorem}
% \begin{proof}[Доказательство нашей теоремы]
% В специальном окружении оформляется доказательство.
% \end{proof}

% \begin{definition}
% Текст определения
% \end{definition}

% \begin{remark}
% Текст замечания
% \end{remark}

% \paragraph{Перечни:} Нумерованные
% \begin{enumerate}
% \item Первый
% \item Второй
% \begin{enumerate}
% \item Вложенный первый
% \item Вложенный второй
% \end{enumerate}
% \end{enumerate}

% Не нумерованные

% \begin{itemize}
% \item Первый
% \item Второй
% \begin{itemize}
% \item Вложенный первый
% \item Вложенный второй
% \end{itemize}
% \end{itemize}


% Здесь текст документа заканчивается
\end{document}
% Начиная с этого момента весь текст LaTeX игнорирует, можете вставлять любую абракадабру.
